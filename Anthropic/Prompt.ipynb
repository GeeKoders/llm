{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc2fec3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: anthropic in /Users/geekoder/anaconda3/envs/llms-practice/lib/python3.11/site-packages (0.61.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/geekoder/anaconda3/envs/llms-practice/lib/python3.11/site-packages (from anthropic) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/geekoder/anaconda3/envs/llms-practice/lib/python3.11/site-packages (from anthropic) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.25.0 in /Users/geekoder/anaconda3/envs/llms-practice/lib/python3.11/site-packages (from anthropic) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/geekoder/anaconda3/envs/llms-practice/lib/python3.11/site-packages (from anthropic) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/geekoder/anaconda3/envs/llms-practice/lib/python3.11/site-packages (from anthropic) (2.11.7)\n",
      "Requirement already satisfied: sniffio in /Users/geekoder/anaconda3/envs/llms-practice/lib/python3.11/site-packages (from anthropic) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in /Users/geekoder/anaconda3/envs/llms-practice/lib/python3.11/site-packages (from anthropic) (4.14.1)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/geekoder/anaconda3/envs/llms-practice/lib/python3.11/site-packages (from anyio<5,>=3.5.0->anthropic) (3.10)\n",
      "Requirement already satisfied: certifi in /Users/geekoder/anaconda3/envs/llms-practice/lib/python3.11/site-packages (from httpx<1,>=0.25.0->anthropic) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/geekoder/anaconda3/envs/llms-practice/lib/python3.11/site-packages (from httpx<1,>=0.25.0->anthropic) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/geekoder/anaconda3/envs/llms-practice/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.25.0->anthropic) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/geekoder/anaconda3/envs/llms-practice/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->anthropic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/geekoder/anaconda3/envs/llms-practice/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->anthropic) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/geekoder/anaconda3/envs/llms-practice/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->anthropic) (0.4.1)\n"
     ]
    }
   ],
   "source": [
    "! pip install anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "441c3390",
   "metadata": {},
   "outputs": [],
   "source": [
    "from anthropic import Anthropic\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5eff517e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "load_dotenv()\n",
    "Anthropic_API_Key = os.getenv(\"Anthropic_API_Key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0442822",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Anthropic(api_key=Anthropic_API_Key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45102a34",
   "metadata": {},
   "source": [
    "# Getting Available Anthropic Models\n",
    "\n",
    "Anthropic currently provides several methods to learn about available models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59f4dba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anthropic Available Models List:\n",
      " 1. claude-3-5-sonnet-20241022\n",
      " 2. claude-3-5-sonnet-20240620\n",
      " 3. claude-3-5-haiku-20241022\n",
      " 4. claude-3-opus-20240229\n",
      " 5. claude-3-sonnet-20240229\n",
      " 6. claude-3-haiku-20240307\n",
      " 7. claude-2.1\n",
      " 8. claude-2.0\n",
      " 9. claude-instant-1.2\n"
     ]
    }
   ],
   "source": [
    "# Method 1: Available models from official documentation (as of 2024)\n",
    "available_models = [\n",
    "    # Claude 3.5 series\n",
    "    \"claude-3-5-sonnet-20241022\",  # Latest version\n",
    "    \"claude-3-5-sonnet-20240620\",  # Previous version\n",
    "    \"claude-3-5-haiku-20241022\",   # Haiku version\n",
    "    \n",
    "    # Claude 3 series\n",
    "    \"claude-3-opus-20240229\",      # Most powerful model\n",
    "    \"claude-3-sonnet-20240229\",    # Balanced performance and cost\n",
    "    \"claude-3-haiku-20240307\",     # Fastest model\n",
    "    \n",
    "    # Legacy versions (may be deprecated)\n",
    "    \"claude-2.1\",\n",
    "    \"claude-2.0\",\n",
    "    \"claude-instant-1.2\"\n",
    "]\n",
    "\n",
    "print(\"Anthropic Available Models List:\")\n",
    "for i, model in enumerate(available_models, 1):\n",
    "    print(f\"{i:2d}. {model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14746be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Model Availability:\n",
      "--------------------------------------------------\n",
      "‚úÖ claude-3-5-sonnet-20241022     Available\n",
      "‚úÖ claude-3-5-haiku-20241022      Available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9f/0frqwc9d6mbcsw62dvmwhd480000gn/T/ipykernel_26073/1617480865.py:5: DeprecationWarning: The model 'claude-3-opus-20240229' is deprecated and will reach end-of-life on January 5th, 2026.\n",
      "Please migrate to a newer model. Visit https://docs.anthropic.com/en/docs/resources/model-deprecations for more information.\n",
      "  response = client.messages.create(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå claude-3-opus-20240229         Model not found or unavailable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9f/0frqwc9d6mbcsw62dvmwhd480000gn/T/ipykernel_26073/1617480865.py:5: DeprecationWarning: The model 'claude-3-sonnet-20240229' is deprecated and will reach end-of-life on July 21st, 2025.\n",
      "Please migrate to a newer model. Visit https://docs.anthropic.com/en/docs/resources/model-deprecations for more information.\n",
      "  response = client.messages.create(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå claude-3-sonnet-20240229       Model not found or unavailable\n",
      "‚úÖ claude-3-haiku-20240307        Available\n"
     ]
    }
   ],
   "source": [
    "# Method 2: Test model availability by attempting API calls\n",
    "def test_model_availability(client, model_name):\n",
    "    \"\"\"Test if a specified model is available\"\"\"\n",
    "    try:\n",
    "        response = client.messages.create(\n",
    "            model=model_name,\n",
    "            max_tokens=10,\n",
    "            messages=[{\"role\": \"user\", \"content\": \"Hi\"}]\n",
    "        )\n",
    "        return True, \"Available\"\n",
    "    except Exception as e:\n",
    "        error_msg = str(e)\n",
    "        if \"model\" in error_msg.lower():\n",
    "            return False, \"Model not found or unavailable\"\n",
    "        else:\n",
    "            return False, f\"Other error: {error_msg[:50]}...\"\n",
    "\n",
    "# Test several main models\n",
    "test_models = [\n",
    "    \"claude-3-5-sonnet-20241022\",\n",
    "    \"claude-3-5-haiku-20241022\", \n",
    "    \"claude-3-opus-20240229\",\n",
    "    \"claude-3-sonnet-20240229\",\n",
    "    \"claude-3-haiku-20240307\"\n",
    "]\n",
    "\n",
    "print(\"Testing Model Availability:\")\n",
    "print(\"-\" * 50)\n",
    "for model in test_models:\n",
    "    available, status = test_model_availability(client, model)\n",
    "    status_icon = \"‚úÖ\" if available else \"‚ùå\"\n",
    "    print(f\"{status_icon} {model:<30} {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6bd43119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed Model Information:\n",
      "================================================================================\n",
      "\n",
      "üìã claude-3-5-sonnet-20241022\n",
      "   Description: Latest Claude 3.5 Sonnet\n",
      "   Capabilities: Balanced reasoning, creative writing, and coding abilities\n",
      "   Context Window: 200K tokens\n",
      "   Best For: General tasks, programming, analysis\n",
      "\n",
      "üìã claude-3-5-haiku-20241022\n",
      "   Description: Fast and economical model\n",
      "   Capabilities: Quick responses, basic tasks\n",
      "   Context Window: 200K tokens\n",
      "   Best For: Simple conversations, quick response needs\n",
      "\n",
      "üìã claude-3-opus-20240229\n",
      "   Description: Most powerful Claude 3 model\n",
      "   Capabilities: Complex reasoning, creative writing, detailed analysis\n",
      "   Context Window: 200K tokens\n",
      "   Best For: Complex tasks, deep analysis, creative projects\n",
      "\n",
      "üìã claude-3-sonnet-20240229\n",
      "   Description: Balanced performance Claude 3 model\n",
      "   Capabilities: Good reasoning and creative abilities\n",
      "   Context Window: 200K tokens\n",
      "   Best For: Daily tasks, medium complexity work\n",
      "\n",
      "üìã claude-3-haiku-20240307\n",
      "   Description: Fastest Claude 3 model\n",
      "   Capabilities: Fast processing, basic conversations\n",
      "   Context Window: 200K tokens\n",
      "   Best For: Quick responses, bulk processing\n"
     ]
    }
   ],
   "source": [
    "# Method 3: Model characteristics and recommended usage\n",
    "model_info = {\n",
    "    \"claude-3-5-sonnet-20241022\": {\n",
    "        \"description\": \"Latest Claude 3.5 Sonnet\",\n",
    "        \"capabilities\": \"Balanced reasoning, creative writing, and coding abilities\",\n",
    "        \"context_window\": \"200K tokens\",\n",
    "        \"best_for\": \"General tasks, programming, analysis\"\n",
    "    },\n",
    "    \"claude-3-5-haiku-20241022\": {\n",
    "        \"description\": \"Fast and economical model\",\n",
    "        \"capabilities\": \"Quick responses, basic tasks\",\n",
    "        \"context_window\": \"200K tokens\", \n",
    "        \"best_for\": \"Simple conversations, quick response needs\"\n",
    "    },\n",
    "    \"claude-3-opus-20240229\": {\n",
    "        \"description\": \"Most powerful Claude 3 model\",\n",
    "        \"capabilities\": \"Complex reasoning, creative writing, detailed analysis\",\n",
    "        \"context_window\": \"200K tokens\",\n",
    "        \"best_for\": \"Complex tasks, deep analysis, creative projects\"\n",
    "    },\n",
    "    \"claude-3-sonnet-20240229\": {\n",
    "        \"description\": \"Balanced performance Claude 3 model\",\n",
    "        \"capabilities\": \"Good reasoning and creative abilities\",\n",
    "        \"context_window\": \"200K tokens\",\n",
    "        \"best_for\": \"Daily tasks, medium complexity work\"\n",
    "    },\n",
    "    \"claude-3-haiku-20240307\": {\n",
    "        \"description\": \"Fastest Claude 3 model\",\n",
    "        \"capabilities\": \"Fast processing, basic conversations\",\n",
    "        \"context_window\": \"200K tokens\",\n",
    "        \"best_for\": \"Quick responses, bulk processing\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Detailed Model Information:\")\n",
    "print(\"=\" * 80)\n",
    "for model_name, info in model_info.items():\n",
    "    print(f\"\\nüìã {model_name}\")\n",
    "    print(f\"   Description: {info['description']}\")\n",
    "    print(f\"   Capabilities: {info['capabilities']}\")\n",
    "    print(f\"   Context Window: {info['context_window']}\")\n",
    "    print(f\"   Best For: {info['best_for']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75980327",
   "metadata": {},
   "source": [
    "## How to Choose the Right Model?\n",
    "\n",
    "### üéØ Choose by Task Type:\n",
    "\n",
    "**Complex Reasoning & Creative Tasks** ‚Üí `claude-3-opus-20240229`\n",
    "- Academic research, complex analysis\n",
    "- Creative writing, storytelling\n",
    "- Complex code architecture design\n",
    "\n",
    "**Daily Work & Programming** ‚Üí `claude-3-5-sonnet-20241022` \n",
    "- Code writing and debugging\n",
    "- Documentation writing\n",
    "- Data analysis and interpretation\n",
    "\n",
    "**Quick Response & Simple Tasks** ‚Üí `claude-3-5-haiku-20241022` or `claude-3-haiku-20240307`\n",
    "- Simple Q&A\n",
    "- Content summarization\n",
    "- Bulk processing\n",
    "\n",
    "### üí∞ Cost Considerations:\n",
    "- **Opus** > **Sonnet** > **Haiku** (price from high to low)\n",
    "- **Latest versions** are usually slightly more expensive but offer better performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f91c472",
   "metadata": {},
   "source": [
    "## ‚ö†Ô∏è Important Note: No Model List API\n",
    "\n",
    "**Anthropic does NOT provide an API endpoint to list available models** (unlike OpenAI's `/models` endpoint).\n",
    "\n",
    "This means:\n",
    "- You cannot programmatically query for available models\n",
    "- Model names must be known in advance from documentation\n",
    "- The only way to test model availability is to attempt an API call\n",
    "- You need to refer to official documentation for current model list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6e663f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Anthropic - NO model list API:\n",
      "   No equivalent to OpenAI's client.models.list()\n",
      "   No /v1/models endpoint available\n",
      "\n",
      "‚úÖ OpenAI - HAS model list API:\n",
      "   client.models.list() - returns all available models\n",
      "   GET https://api.openai.com/v1/models\n",
      "\n",
      "üìã Current workarounds for Anthropic:\n",
      "   1. Hardcode model names from documentation\n",
      "   2. Test each model with a small API call\n",
      "   3. Check official docs regularly for updates\n",
      "   4. Monitor Anthropic's changelog/announcements\n"
     ]
    }
   ],
   "source": [
    "# Comparison: OpenAI vs Anthropic API for listing models\n",
    "\n",
    "print(\"‚ùå Anthropic - NO model list API:\")\n",
    "print(\"   No equivalent to OpenAI's client.models.list()\")\n",
    "print(\"   No /v1/models endpoint available\")\n",
    "print()\n",
    "\n",
    "print(\"‚úÖ OpenAI - HAS model list API:\")\n",
    "print(\"   client.models.list() - returns all available models\")\n",
    "print(\"   GET https://api.openai.com/v1/models\")\n",
    "print()\n",
    "\n",
    "print(\"üìã Current workarounds for Anthropic:\")\n",
    "print(\"   1. Hardcode model names from documentation\")\n",
    "print(\"   2. Test each model with a small API call\")\n",
    "print(\"   3. Check official docs regularly for updates\")\n",
    "print(\"   4. Monitor Anthropic's changelog/announcements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "295cba8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Checking Anthropic client methods:\n",
      "\n",
      "Available methods on Anthropic client:\n",
      "   - AI_PROMPT\n",
      "   - HUMAN_PROMPT\n",
      "   - api_key\n",
      "   - auth_headers\n",
      "   - auth_token\n",
      "   - base_url\n",
      "   - beta\n",
      "   - close\n",
      "   - completions\n",
      "   - copy\n",
      "   - custom_auth\n",
      "   - default_headers\n",
      "   - default_query\n",
      "   - delete\n",
      "   - get\n",
      "   - get_api_list\n",
      "   - is_closed\n",
      "   - max_retries\n",
      "   - messages\n",
      "   - models\n",
      "   - patch\n",
      "   - platform_headers\n",
      "   - post\n",
      "   - put\n",
      "   - qs\n",
      "   - request\n",
      "   - timeout\n",
      "   - user_agent\n",
      "   - with_options\n",
      "   - with_raw_response\n",
      "   - with_streaming_response\n",
      "\n",
      "üîé Looking for model-related methods:\n",
      "   Found model-related methods: ['models']\n",
      "\n",
      "üìù Available main endpoints:\n",
      "   ‚úÖ client.messages\n",
      "   ‚úÖ client.completions\n",
      "   ‚ùå client.chat\n",
      "\n",
      "‚úÖ client.models exists: <class 'anthropic.resources.models.Models'>\n",
      "   Methods: ['list', 'retrieve', 'with_raw_response', 'with_streaming_response']\n"
     ]
    }
   ],
   "source": [
    "# Let's verify that Anthropic client doesn't have a models list method\n",
    "print(\"üîç Checking Anthropic client methods:\")\n",
    "print()\n",
    "\n",
    "# Check available methods on the client\n",
    "client_methods = [method for method in dir(client) if not method.startswith('_')]\n",
    "print(\"Available methods on Anthropic client:\")\n",
    "for method in client_methods:\n",
    "    print(f\"   - {method}\")\n",
    "\n",
    "print()\n",
    "print(\"üîé Looking for model-related methods:\")\n",
    "model_methods = [method for method in client_methods if 'model' in method.lower()]\n",
    "if model_methods:\n",
    "    print(\"   Found model-related methods:\", model_methods)\n",
    "else:\n",
    "    print(\"   ‚ùå No model-related methods found!\")\n",
    "\n",
    "print()\n",
    "print(\"üìù Available main endpoints:\")\n",
    "main_endpoints = ['messages', 'completions', 'chat']\n",
    "for endpoint in main_endpoints:\n",
    "    if hasattr(client, endpoint):\n",
    "        print(f\"   ‚úÖ client.{endpoint}\")\n",
    "    else:\n",
    "        print(f\"   ‚ùå client.{endpoint}\")\n",
    "\n",
    "# Check if there's a models attribute\n",
    "if hasattr(client, 'models'):\n",
    "    print(f\"\\n‚úÖ client.models exists: {type(client.models)}\")\n",
    "    models_methods = [method for method in dir(client.models) if not method.startswith('_')]\n",
    "    print(\"   Methods:\", models_methods)\n",
    "else:\n",
    "    print(\"\\n‚ùå client.models does not exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "89a74ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéâ Testing client.models.list():\n",
      "\n",
      "‚úÖ SUCCESS! Models retrieved:\n",
      "   Type: <class 'anthropic.pagination.SyncPage[ModelInfo]'>\n",
      "   Length: 8\n",
      "\n",
      "üìã Available models:\n",
      "    1. claude-opus-4-1-20250805\n",
      "    2. claude-opus-4-20250514\n",
      "    3. claude-sonnet-4-20250514\n",
      "    4. claude-3-7-sonnet-20250219\n",
      "    5. claude-3-5-sonnet-20241022\n",
      "    6. claude-3-5-haiku-20241022\n",
      "    7. claude-3-5-sonnet-20240620\n",
      "    8. claude-3-haiku-20240307\n"
     ]
    }
   ],
   "source": [
    "# üéâ DISCOVERY: Anthropic DOES have a models API!\n",
    "print(\"üéâ Testing client.models.list():\")\n",
    "print()\n",
    "\n",
    "try:\n",
    "    models = client.models.list()\n",
    "    print(\"‚úÖ SUCCESS! Models retrieved:\")\n",
    "    print(f\"   Type: {type(models)}\")\n",
    "    print(f\"   Length: {len(models.data) if hasattr(models, 'data') else 'N/A'}\")\n",
    "    print()\n",
    "    \n",
    "    if hasattr(models, 'data'):\n",
    "        print(\"üìã Available models:\")\n",
    "        for i, model in enumerate(models.data, 1):\n",
    "            print(f\"   {i:2d}. {model.id}\")\n",
    "            if hasattr(model, 'created'):\n",
    "                print(f\"       Created: {model.created}\")\n",
    "            if hasattr(model, 'owned_by'):\n",
    "                print(f\"       Owner: {model.owned_by}\")\n",
    "    else:\n",
    "        print(\"üìã Models object:\", models)\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå ERROR: {e}\")\n",
    "    print(f\"   Error type: {type(e)}\")\n",
    "    print()\n",
    "    print(\"This might mean:\")\n",
    "    print(\"   - The API endpoint exists but requires special permissions\")\n",
    "    print(\"   - The feature is not yet fully implemented\")\n",
    "    print(\"   - There's an API version issue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c56474d",
   "metadata": {},
   "source": [
    "## üéØ UPDATED: Best Practice for Getting Models\n",
    "\n",
    "**‚úÖ Anthropic DOES provide a models API!**\n",
    "\n",
    "### Method 4: Use the Official Models API (RECOMMENDED)\n",
    "\n",
    "```python\n",
    "# The official way to get current models\n",
    "models = client.models.list()\n",
    "for model in models.data:\n",
    "    print(model.id)\n",
    "```\n",
    "\n",
    "### New Discoveries:\n",
    "- üÜï **Claude Opus 4.1** (`claude-opus-4-1-20250805`) - Latest!\n",
    "- üÜï **Claude Opus 4** (`claude-opus-4-20250514`)  \n",
    "- üÜï **Claude Sonnet 4** (`claude-sonnet-4-20250514`)\n",
    "- üÜï **Claude 3.7 Sonnet** (`claude-3-7-sonnet-20250219`)\n",
    "\n",
    "### Why use the API method?\n",
    "- ‚úÖ Always up-to-date\n",
    "- ‚úÖ Shows actual available models for your account\n",
    "- ‚úÖ No need to hardcode model names\n",
    "- ‚úÖ Programmatically discoverable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9eb0ff26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Current Available Models:\n",
      "==================================================\n",
      " 1. claude-opus-4-1-20250805\n",
      " 2. claude-opus-4-20250514\n",
      " 3. claude-sonnet-4-20250514\n",
      " 4. claude-3-7-sonnet-20250219\n",
      " 5. claude-3-5-sonnet-20241022\n",
      " 6. claude-3-5-haiku-20241022\n",
      " 7. claude-3-5-sonnet-20240620\n",
      " 8. claude-3-haiku-20240307\n",
      "\n",
      "Total: 8 models available\n"
     ]
    }
   ],
   "source": [
    "# Final: Simple function to get current available models\n",
    "def get_anthropic_models(client):\n",
    "    \"\"\"Get current available Anthropic models\"\"\"\n",
    "    try:\n",
    "        models = client.models.list()\n",
    "        return [model.id for model in models.data]\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting models: {e}\")\n",
    "        return []\n",
    "\n",
    "# Use it\n",
    "current_models = get_anthropic_models(client)\n",
    "print(\"üöÄ Current Available Models:\")\n",
    "print(\"=\" * 50)\n",
    "for i, model in enumerate(current_models, 1):\n",
    "    print(f\"{i:2d}. {model}\")\n",
    "\n",
    "print(f\"\\nTotal: {len(current_models)} models available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af95ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.messages.create(\n",
    "    model=\"claude-3-5-sonnet-20241022\",\n",
    "    max_tokens=100,\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Hello, how are you?\"}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6796e489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Message(id='msg_01LjCtcPkQXMnTxwg7X4em4J', content=[TextBlock(citations=None, text=\"Hi! I'm doing well, thanks for asking. How are you today?\", type='text')], model='claude-3-5-sonnet-20241022', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=Usage(cache_creation_input_tokens=0, cache_read_input_tokens=0, input_tokens=13, output_tokens=19, server_tool_use=None, service_tier='standard'))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45114de5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Message(id='msg_01EZRvq4BXMWixSdB5NzVDi4', content=[TextBlock(citations=None, text=\"I'm doing well, thank you! How are you today?\", type='text')], model='claude-3-5-sonnet-20241022', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=Usage(cache_creation_input_tokens=0, cache_read_input_tokens=0, input_tokens=13, output_tokens=16, server_tool_use=None, service_tier='standard'))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_text = response.content[0].text\n",
    "response_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5437ad60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm doing well, thank you! How are you today?\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8de9385e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_assistant_message(messages, text):\n",
    "    assistant_message = {\"role\": \"assistant\", \"content\": text}\n",
    "    messages.append(assistant_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5a6e9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(messages):\n",
    "    response = client.messages.create(\n",
    "        model=\"claude-3-5-sonnet-20241022\",\n",
    "        max_tokens=100,\n",
    "        messages = messages\n",
    "    )\n",
    "\n",
    "    return response.content[0].text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49855761",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "add_user_message(messages, \"Define quantium computing in one sentence\")\n",
    "answer = chat(messages)\n",
    "add_assistant_message(messages, answer)\n",
    "add_user_message(messages, \"Write another sentence\")\n",
    "final_answer = chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca16f89b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Quantum computers harness the strange laws of quantum mechanics to process information in ways that classical computers cannot, enabling parallel computations and the potential to revolutionize fields like cryptography, drug discovery, and optimization problems.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3bc6dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms-practice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
